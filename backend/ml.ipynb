{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stella's Notes: This is the .py file Stella is currently using to write the NLP code for the project.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from flask import Flask, render_template, request\n",
    "from flask_cors import CORS\n",
    "from helpers.MySQLDatabaseHandler import MySQLDatabaseHandler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spotify_df = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")\n",
    "lyric_df = pd.read_csv(\"/Users/juanruzhang/4300/4300-JSON-wanderingmelody/backend/spotify_millsongdata.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General outline:\n",
    "- Need to categorize weather into different sentiments (E.g sunny = happy, windy = fast paced? etc)\n",
    "- How to relate location to song? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Look at her face, it's a wonderful face  \\r\\nA...\n",
       "1        Take it easy with me, please  \\r\\nTouch me gen...\n",
       "2        I'll never know why I had to go  \\r\\nWhy I had...\n",
       "3        Making somebody happy is a question of give an...\n",
       "4        Making somebody happy is a question of give an...\n",
       "                               ...                        \n",
       "57645    Irie days come on play  \\r\\nLet the angels fly...\n",
       "57646    Power to the workers  \\r\\nMore power  \\r\\nPowe...\n",
       "57647    all you need  \\r\\nis something i'll believe  \\...\n",
       "57648    northern star  \\r\\nam i frightened  \\r\\nwhere ...\n",
       "57649    come in  \\r\\nmake yourself at home  \\r\\ni'm a ...\n",
       "Name: text, Length: 57650, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from collections.abc import Callable\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Returns a list of words that make up the text.\n",
    "    \n",
    "    Note: for simplicity, lowercase everything. Do not remove duplicate words.\n",
    "    Requirement: Use Regex to satisfy this function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input string to be tokenized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        A list of strings representing the words in the text.\n",
    "    \"\"\"\n",
    "    outcome = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lyrics = lyric_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_lyrics = {i: row for i, row in enumerate(lyric_df.to_dict(orient='records'))}\n",
    "#A dictionary of dictionaries. \n",
    "#Key: Row number. Value: Dict of {artist:..., link:...., song:..., text:...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(dict_of_lyrics, tokenize_method: Callable[[str], List[str]]):\n",
    "    tokenized_lyrics = {}\n",
    "    nrows = len(lyric_df)\n",
    "    for i in range(nrows):\n",
    "        lyrics = dict_of_lyrics[i]['text']\n",
    "        tokenized_lyrics[i] = tokenize_method(lyrics)\n",
    "    return tokenized_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_lyrics = tokenize_lyrics(dict_of_lyrics, tokenize)\n",
    "#A dict with the row numbers of lyric_df as keys and the lsit of tokenized lyrics as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_word_song_count(tokenize_method: Callable[[str], List[str]],\n",
    "    tokenized_lyrics: Dict[int, List[str]]):\n",
    "    \"\"\"Returns a dictionary with the row numbers of songs each distinct word appears in as VALUEs and distinct words as KEYS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenize_method : Callable[[str], List[str]]\n",
    "        A method to tokenize a string into a list of strings representing words.\n",
    "    tokenized_lyrics: \n",
    "        A dict with the row numbers of lyric_df as keys and the lsit of tokenized lyrics as value\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, int]\n",
    "        A dictionary of words mapped to the number of songs they appear in.\n",
    "    \"\"\"\n",
    "    song_count = {}\n",
    "    \n",
    "    for key in tokenized_lyrics:\n",
    "        unique_tokens = set(token.casefold() for token in tokenized_lyrics[key])\n",
    "\n",
    "        for token in unique_tokens:\n",
    "            if token not in song_count:\n",
    "                song_count[token] = set()\n",
    "            song_count[token].add(key)\n",
    "\n",
    "    return song_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_count = build_word_song_count(tokenize, tokenized_lyrics)\n",
    "# A dict with KEYS as unique words and VALUES as a list of all the songs(their row numbers) the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juanruzhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(list_of_stop_words,tokenized_lyrics):\n",
    "    \n",
    "    \"\"\"Returns a dictionary with KEYS as row values and VALUES as lyrics without stop words\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_stop_words : A list of stop words(E.g and, so, the....)\n",
    "    tokenized_lyrics: \n",
    "        A dict with the row numbers of lyric_df as KEYS and the list of tokenized lyrics as VALUE\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, int]\n",
    "        A dictionary of row numbers mapped to the cleaned tokenized lyrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_stop_words = set()\n",
    "    for word in list_of_stop_words:\n",
    "        clean_stop_words.update(nltk.word_tokenize(word.lower()))  \n",
    "    \n",
    "    stop_word_removed_lyrics = {}\n",
    "    \n",
    "    for i, lyrics in tokenized_lyrics.items():\n",
    "        cleaned_lyrics = [word for word in lyrics if word.lower() not in clean_stop_words]\n",
    "        stop_word_removed_lyrics[i] = cleaned_lyrics\n",
    "                \n",
    "    return stop_word_removed_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokenized_lyrics = remove_stop_words(stopwords.words('english'),tokenized_lyrics)\n",
    "#A dictionary of row numbers mapped to the cleaned tokenized lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_input(tokenize,list_of_stop_words,input_words):\n",
    "    \n",
    "    \"\"\"Returns a dictionary with KEYS as row values and VALUES as lyrics without stop words\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_stop_words : A list of stop words(E.g and, so, the....)\n",
    "    input_words: A string(The input)\n",
    "    Returns\n",
    "    -------\n",
    "    A LIST of tokenized words with stop words removed\n",
    "    \"\"\"\n",
    "    list_tokens = tokenize(input_words)\n",
    "    cleaned_words = [word for word in list_tokens if word not in list_of_stop_words]\n",
    "    \n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_song_count = build_word_song_count(tokenize, cleaned_tokenized_lyrics)\n",
    "# A dict with KEYS as unique NON STOP words and VALUES as a list of all the songs(their row numbers) the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Long runtime\n",
    "def create_j_sim_mat(input_dict) -> np.ndarray:\n",
    "    \"\"\"Create Jaccard similarity matrix for songs.\n",
    "    Create Jaccard similarity matrix, a np.ndarray of size (`len(lyric_df)`, `len(lyric_df)`),\n",
    "    computing the character similarity, where the entry (i, j) indicating the Jaccard similarity\n",
    "    between the songs `i` and `j`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dict: input dictionary of KEYS as song row numbers and VALUES as their lyrics\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The Jaccard similarity matrix of (`number of rows`, `number of rows`), with the entry\n",
    "        (i, j) indicating the Jaccard similarity between the songs `i` and `j`.\n",
    "    \"\"\"\n",
    "    return_matrix = np.zeros((len(lyric_df),len(lyric_df)))\n",
    "\n",
    "    for song_index in input_dict:\n",
    "      for other_song_index in input_dict:\n",
    "        song_words = set(input_dict[song_index])\n",
    "        other_song_words = set(input_dict[other_song_index])\n",
    "        union = song_words | other_song_words\n",
    "        intersection = song_words & other_song_words\n",
    "        value = (len(intersection)-1)/(len(union)-1) \n",
    "        return_matrix[song_index][other_song_index] = value\n",
    "    \n",
    "    return return_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_inverted_index(songs: dict) -> dict:\n",
    "    \"\"\"Builds an inverted index from the song lyrics.\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "\n",
    "    songs: dict\n",
    "        A dictionary where keys are song numbers and values are lists of tokens (words from the lyrics).\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "\n",
    "    inverted_index: dict\n",
    "        An inverted index mapping each term to a sorted list of tuples (song_number, term_frequency):\n",
    "        inverted_index[term] = [(s1, tf1), (s2, tf2), ...]\n",
    "\n",
    "    Example\n",
    "    =======\n",
    "\n",
    "    >> songs = {\n",
    "    ...    1: ['love', 'me', 'do', 'love', 'love'],\n",
    "    ...    2: ['hello', 'goodbye', 'hello']\n",
    "    ... }\n",
    "\n",
    "    >> idx = build_inverted_index(songs)\n",
    "\n",
    "    >> idx['love']\n",
    "    [(1, 3)]\n",
    "\n",
    "    >> idx['hello']\n",
    "    [(2, 2)]\n",
    "    \"\"\"\n",
    "    inverted_index = {}\n",
    "\n",
    "    for song_num, tokens in songs.items():\n",
    "        token_counts = {}\n",
    "        \n",
    "        for token in tokens:\n",
    "            token_counts[token] = token_counts.get(token, 0) + 1\n",
    "        \n",
    "        for token, count in token_counts.items():\n",
    "            if token not in inverted_index:\n",
    "                inverted_index[token] = []\n",
    "            inverted_index[token].append((song_num, count))\n",
    "\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_idf(inv_idx, n_docs, min_df=0, max_df_ratio=1):\n",
    "    \"\"\"Compute term IDF values from the inverted index.\n",
    "    Words that are too frequent or too infrequent get pruned.\n",
    "\n",
    "    Hint: Make sure to use log base 2.\n",
    "\n",
    "    inv_idx: an inverted index as above\n",
    "\n",
    "    n_docs: int,\n",
    "        The number of songs.\n",
    "\n",
    "    min_df: int,\n",
    "        Minimum number of documents a term must occur in.\n",
    "        Less frequent words get ignored.\n",
    "        Documents that appear min_df number of times should be included.\n",
    "\n",
    "    max_df_ratio: float,\n",
    "        Maximum ratio of documents a term can occur in.\n",
    "        More frequent words get ignored.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "\n",
    "    idf: dict\n",
    "        For each term, the dict contains the idf value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO-5.1\n",
    "    return_dict = {}\n",
    "    \n",
    "    for word, word_list in inv_idx.items():\n",
    "        word_count = len(word_list)\n",
    "        \n",
    "        if word_count >= min_df and word_count / n_docs <= max_df_ratio:\n",
    "            idf = math.log2(n_docs/(1+word_count))\n",
    "            return_dict[word] = idf\n",
    "                \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = build_inverted_index(cleaned_tokenized_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf = compute_idf(inverted_index, len(lyric_df), min_df=0, max_df_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'we'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtdidf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'we'"
     ]
    }
   ],
   "source": [
    "print(tdidf[\"we\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dis(list_of_words):\n",
    "    \"\"\"How many times each word appears within a given text. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_words: a list of tokenized words\n",
    "    \"\"\"\n",
    "    fd = nltk.FreqDist(list_of_words)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      "nd girl makes feel fine ever believe mine kind girl without blue ever leaves g\n",
      "nd girl makes feel fine ever believe mine kind girl without blue ever leaves\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(cleaned_tokenized_lyrics[0])\n",
    "text.concordance(\"mine\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigrams: Frequent two-word combinations\n",
    "#Trigrams: Frequent three-word combinations\n",
    "#Quadgrams: Frequent four-word combinations\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(text)\n",
    "result = finder.ngram_fd.most_common(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/juanruzhang/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.457, 'pos': 0.543, 'compound': 0.7134}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"Wow, NLTK is not not not terrible!\")\n",
    "# compound ranges from -1 (most negative) to +1 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_word_sentiments(list_of_words):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        list_of_words (_type_): list of words\n",
    "\n",
    "    Returns:\n",
    "        a dictionary with KEYS as positive, negative, neutral and VALUES of sets of words that belong to each category\n",
    "    \"\"\"\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "\n",
    "    for word in list_of_words:\n",
    "        score = sia.polarity_scores(word)[\"compound\"]\n",
    "        if score > 0:\n",
    "            positive.append(word)\n",
    "        elif score < 0:\n",
    "            negative.append(word)\n",
    "        else:\n",
    "            neutral.append(word)\n",
    "    \n",
    "    return {\"positive\":positive, \"negative\":negative, \"neutral\":neutral}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms_of_word(word):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        word (_type_): word\n",
    "\n",
    "    Returns:\n",
    "        _type_: a set of all the synonyms of the word\n",
    "    \"\"\"\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name().replace(\"_\", \" \").lower())\n",
    "\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "2285\n",
      "2732\n",
      "3226\n",
      "3337\n",
      "3378\n",
      "9015\n",
      "9557\n",
      "9581\n",
      "10116\n",
      "10518\n",
      "11146\n",
      "11169\n",
      "11898\n",
      "12131\n",
      "13034\n",
      "13342\n",
      "13643\n",
      "15670\n",
      "15914\n",
      "15933\n",
      "17241\n",
      "17406\n",
      "17763\n",
      "18303\n",
      "20325\n",
      "20507\n",
      "21311\n",
      "24165\n",
      "24533\n",
      "24769\n",
      "25883\n",
      "26151\n",
      "26910\n",
      "27062\n",
      "27114\n",
      "27259\n",
      "27769\n",
      "30687\n",
      "31697\n",
      "34153\n",
      "36810\n",
      "37041\n",
      "37267\n",
      "40140\n",
      "41659\n",
      "41665\n",
      "43227\n",
      "43810\n",
      "49969\n",
      "50887\n",
      "51074\n",
      "51129\n",
      "52904\n",
      "52991\n",
      "53235\n",
      "53290\n",
      "55768\n",
      "56248\n",
      "56836\n"
     ]
    }
   ],
   "source": [
    "for key in cleaned_tokenized_lyrics:\n",
    "    if \"love you\" in \" \".join(cleaned_tokenized_lyrics[key]):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming words\n",
    "ps = PorterStemmer()\n",
    "ps.stem(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Get inputs\n",
    "2: Use genre to search for songs\n",
    "3: Find exact matching words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exact matching words \n",
    "# \"genre_input\" is the user inputted genre\n",
    "user_genre_input = \"placeholder input\"\n",
    "\n",
    "clean_genre_input = remove_stop_words(stopwords.words('english'),{0:tokenize(user_genre_input)})\n",
    "\n",
    "possible_songs_dict = {}\n",
    "\n",
    "for word in clean_genre_input[0]:\n",
    "    if clean_song_count.get(word) is not None:\n",
    "        possible_songs_dict[word] = clean_song_count[word]\n",
    "\n",
    "if len(possible_songs_dict) > 0:\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
