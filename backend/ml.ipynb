{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flask, render_template, request\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflask_cors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CORS\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMySQLDatabaseHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MySQLDatabaseHandler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "#Stella's Notes: This is the .py file Stella is currently using to write the NLP code for the project.\n",
    "#Need to do:\n",
    "#Incorporate age \n",
    "#How to save cleaned/stemmed/tokenized lyrics as df? How to save the dicts/inverted indexes etc as well?\n",
    "#How to prioritize certain words above others. Should I even do this? E.g if someone enter \"happy Monday\", should I prioritize happy or Monday?\n",
    "#How to semantically relate words? E.g cold with frozen, etc\n",
    "#Handle misspelled words\n",
    "\n",
    "#Create a datasets for: cleaned lyrics, tokenized lyrics, lyric polarized score, other essential stuff.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from flask import Flask, render_template, request\n",
    "from flask_cors import CORS\n",
    "from helpers.MySQLDatabaseHandler import MySQLDatabaseHandler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spotify_df = pd.read_csv(\"backend/spotify-tracks-dataset.csv\")\n",
    "lyric_df = pd.read_csv(\"/Users/juanruzhang/4300/4300-JSON-wanderingmelody/backend/spotify_millsongdata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Look at her face, it's a wonderful face  \\r\\nA...\n",
       "1        Take it easy with me, please  \\r\\nTouch me gen...\n",
       "2        I'll never know why I had to go  \\r\\nWhy I had...\n",
       "3        Making somebody happy is a question of give an...\n",
       "4        Making somebody happy is a question of give an...\n",
       "                               ...                        \n",
       "57645    Irie days come on play  \\r\\nLet the angels fly...\n",
       "57646    Power to the workers  \\r\\nMore power  \\r\\nPowe...\n",
       "57647    all you need  \\r\\nis something i'll believe  \\...\n",
       "57648    northern star  \\r\\nam i frightened  \\r\\nwhere ...\n",
       "57649    come in  \\r\\nmake yourself at home  \\r\\ni'm a ...\n",
       "Name: text, Length: 57650, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from collections.abc import Callable\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Returns a list of words that make up the text.\n",
    "    \n",
    "    Note: for simplicity, lowercase everything. Do not remove duplicate words.\n",
    "    Requirement: Use Regex to satisfy this function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The input string to be tokenized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        A list of strings representing the words in the text.\n",
    "    \"\"\"\n",
    "    outcome = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lyrics = lyric_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_lyrics = {i: row for i, row in enumerate(lyric_df.to_dict(orient='records'))}\n",
    "#A dictionary of dictionaries. \n",
    "#Key: Row number. Value: Dict of {artist:..., link:...., song:..., text:...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(dict_of_lyrics, tokenize_method: Callable[[str], List[str]]):\n",
    "    tokenized_lyrics = {}\n",
    "    nrows = len(lyric_df)\n",
    "    for i in range(nrows):\n",
    "        lyrics = dict_of_lyrics[i]['text']\n",
    "        tokenized_lyrics[i] = tokenize_method(lyrics)\n",
    "    return tokenized_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_lyrics = tokenize_lyrics(dict_of_lyrics, tokenize)\n",
    "#A dict with the row numbers of lyric_df as keys and the lsit of tokenized lyrics as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_word_song_count(tokenize_method: Callable[[str], List[str]],\n",
    "    tokenized_lyrics: Dict[int, List[str]]):\n",
    "    \"\"\"Returns a dictionary with the row numbers of songs each distinct word appears in as VALUEs and distinct words as KEYS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenize_method : Callable[[str], List[str]]\n",
    "        A method to tokenize a string into a list of strings representing words.\n",
    "    tokenized_lyrics: \n",
    "        A dict with the row numbers of lyric_df as keys and the lsit of tokenized lyrics as value\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, int]\n",
    "        A dictionary of words mapped to the number of songs they appear in.\n",
    "    \"\"\"\n",
    "    song_count = {}\n",
    "    \n",
    "    for key in tokenized_lyrics:\n",
    "        unique_tokens = set(token.casefold() for token in tokenized_lyrics[key])\n",
    "\n",
    "        for token in unique_tokens:\n",
    "            if token not in song_count:\n",
    "                song_count[token] = set()\n",
    "            song_count[token].add(key)\n",
    "\n",
    "    return song_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_count = build_word_song_count(tokenize, tokenized_lyrics)\n",
    "# A dict with KEYS as unique words and VALUES as a list of all the songs(their row numbers) the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(list_of_stop_words,tokenized_lyrics):\n",
    "    \n",
    "    \"\"\"Returns a dictionary with KEYS as row values and VALUES as lyrics without stop words\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_stop_words : A list of stop words(E.g and, so, the....)\n",
    "    tokenized_lyrics: \n",
    "        A dict with the row numbers of lyric_df as KEYS and the list of tokenized lyrics as VALUE\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, int]\n",
    "        A dictionary of row numbers mapped to the cleaned tokenized lyrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_stop_words = set()\n",
    "    for word in list_of_stop_words:\n",
    "        clean_stop_words.update(nltk.word_tokenize(word.lower()))  \n",
    "    \n",
    "    stop_word_removed_lyrics = {}\n",
    "    \n",
    "    for i, lyrics in tokenized_lyrics.items():\n",
    "        cleaned_lyrics = [word for word in lyrics if word.lower() not in clean_stop_words]\n",
    "        stop_word_removed_lyrics[i] = cleaned_lyrics\n",
    "                \n",
    "    return stop_word_removed_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokenized_lyrics = remove_stop_words(stopwords.words('english'),tokenized_lyrics)\n",
    "#A dictionary of row numbers mapped to the cleaned tokenized lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_input(tokenize,list_of_stop_words,input_words):\n",
    "    \n",
    "    \"\"\"Returns a dictionary with KEYS as row values and VALUES as lyrics without stop words\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_stop_words : A list of stop words(E.g and, so, the....)\n",
    "    input_words: A string(The input)\n",
    "    Returns\n",
    "    -------\n",
    "    A LIST of tokenized words with stop words removed\n",
    "    \"\"\"\n",
    "    list_tokens = tokenize(input_words)\n",
    "    cleaned_words = [word for word in list_tokens if word not in list_of_stop_words]\n",
    "    \n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_song_count = build_word_song_count(tokenize, cleaned_tokenized_lyrics)\n",
    "# A dict with KEYS as unique NON STOP words and VALUES as a list of all the songs(their row numbers) the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Long runtime\n",
    "def create_j_sim_mat(input_dict) -> np.ndarray:\n",
    "    \"\"\"Create Jaccard similarity matrix for songs.\n",
    "    Create Jaccard similarity matrix, a np.ndarray of size (`len(lyric_df)`, `len(lyric_df)`),\n",
    "    computing the character similarity, where the entry (i, j) indicating the Jaccard similarity\n",
    "    between the songs `i` and `j`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dict: input dictionary of KEYS as song row numbers and VALUES as their lyrics\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The Jaccard similarity matrix of (`number of rows`, `number of rows`), with the entry\n",
    "        (i, j) indicating the Jaccard similarity between the songs `i` and `j`.\n",
    "    \"\"\"\n",
    "    return_matrix = np.zeros((len(lyric_df),len(lyric_df)))\n",
    "\n",
    "    for song_index in input_dict:\n",
    "      for other_song_index in input_dict:\n",
    "        song_words = set(input_dict[song_index])\n",
    "        other_song_words = set(input_dict[other_song_index])\n",
    "        union = song_words | other_song_words\n",
    "        intersection = song_words & other_song_words\n",
    "        value = (len(intersection)-1)/(len(union)-1) \n",
    "        return_matrix[song_index][other_song_index] = value\n",
    "    \n",
    "    return return_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_inverted_index(songs: dict) -> dict:\n",
    "    \"\"\"Builds an inverted index from the song lyrics.\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "\n",
    "    songs: dict\n",
    "        A dictionary where keys are song numbers and values are lists of tokens (words from the lyrics).\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "\n",
    "    inverted_index: dict\n",
    "        An inverted index mapping each term to a sorted list of tuples (song_number, term_frequency):\n",
    "        inverted_index[term] = [(s1, tf1), (s2, tf2), ...]\n",
    "\n",
    "    Example\n",
    "    =======\n",
    "\n",
    "    >> songs = {\n",
    "    ...    1: ['love', 'me', 'do', 'love', 'love'],\n",
    "    ...    2: ['hello', 'goodbye', 'hello']\n",
    "    ... }\n",
    "\n",
    "    >> idx = build_inverted_index(songs)\n",
    "\n",
    "    >> idx['love']\n",
    "    [(1, 3),(2,2)....]\n",
    "\n",
    "    >> idx['hello']\n",
    "    [(2, 2)]\n",
    "    \"\"\"\n",
    "    inverted_index = {}\n",
    "\n",
    "    for song_num, tokens in songs.items():\n",
    "        token_counts = {}\n",
    "        \n",
    "        for token in tokens:\n",
    "            token_counts[token] = token_counts.get(token, 0) + 1\n",
    "        \n",
    "        for token, count in token_counts.items():\n",
    "            if token not in inverted_index:\n",
    "                inverted_index[token] = []\n",
    "            inverted_index[token].append((song_num, count))\n",
    "\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_idf(inv_idx, n_docs, min_df=0, max_df_ratio=1):\n",
    "    \"\"\"Compute term IDF values from the inverted index.\n",
    "    Words that are too frequent or too infrequent get pruned.\n",
    "\n",
    "    Hint: Make sure to use log base 2.\n",
    "\n",
    "    inv_idx: an inverted index as above\n",
    "\n",
    "    n_docs: int,\n",
    "        The number of songs.\n",
    "\n",
    "    min_df: int,\n",
    "        Minimum number of documents a term must occur in.\n",
    "        Less frequent words get ignored.\n",
    "        Documents that appear min_df number of times should be included.\n",
    "\n",
    "    max_df_ratio: float,\n",
    "        Maximum ratio of documents a term can occur in.\n",
    "        More frequent words get ignored.\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "\n",
    "    idf: dict\n",
    "        For each term, the dict contains the idf value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO-5.1\n",
    "    return_dict = {}\n",
    "    \n",
    "    for word, word_list in inv_idx.items():\n",
    "        word_count = len(word_list)\n",
    "        \n",
    "        if word_count >= min_df and word_count / n_docs <= max_df_ratio:\n",
    "            idf = math.log2(n_docs/(1+word_count))\n",
    "            return_dict[word] = idf\n",
    "                \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = build_inverted_index(cleaned_tokenized_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf = compute_idf(inverted_index, len(lyric_df), min_df=0, max_df_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dis(list_of_words):\n",
    "    \"\"\"How many times each word appears within a given text. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_words: a list of tokenized words\n",
    "    \"\"\"\n",
    "    fd = nltk.FreqDist(list_of_words)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      "nd girl makes feel fine ever believe mine kind girl without blue ever leaves g\n",
      "nd girl makes feel fine ever believe mine kind girl without blue ever leaves\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(cleaned_tokenized_lyrics[0])\n",
    "text.concordance(\"mine\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigrams: Frequent two-word combinations\n",
    "#Trigrams: Frequent three-word combinations\n",
    "#Quadgrams: Frequent four-word combinations\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(text)\n",
    "result = finder.ngram_fd.most_common(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/juanruzhang/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.457, 'pos': 0.543, 'compound': 0.7134}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"Wow, NLTK is not not not terrible!\")\n",
    "# compound ranges from -1 (most negative) to +1 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_word_sentiments(list_of_words):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        list_of_words (_type_): list of words\n",
    "\n",
    "    Returns:\n",
    "        a dictionary with KEYS as positive, negative, neutral and VALUES of sets of words that belong to each category\n",
    "    \"\"\"\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "\n",
    "    for word in list_of_words:\n",
    "        score = sia.polarity_scores(word)[\"compound\"]\n",
    "        if score > 0:\n",
    "            positive.append(word)\n",
    "        elif score < 0:\n",
    "            negative.append(word)\n",
    "        else:\n",
    "            neutral.append(word)\n",
    "    \n",
    "    return {\"positive\":positive, \"negative\":negative, \"neutral\":neutral}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms_of_word(word):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        word (_type_): word\n",
    "\n",
    "    Returns:\n",
    "        _type_: a set of all the synonyms of the word\n",
    "    \"\"\"\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name().replace(\"_\", \" \").lower())\n",
    "\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "2285\n",
      "2732\n",
      "3226\n",
      "3337\n",
      "3378\n",
      "9015\n",
      "9557\n",
      "9581\n",
      "10116\n",
      "10518\n",
      "11146\n",
      "11169\n",
      "11898\n",
      "12131\n",
      "13034\n",
      "13342\n",
      "13643\n",
      "15670\n",
      "15914\n",
      "15933\n",
      "17241\n",
      "17406\n",
      "17763\n",
      "18303\n",
      "20325\n",
      "20507\n",
      "21311\n",
      "24165\n",
      "24533\n",
      "24769\n",
      "25883\n",
      "26151\n",
      "26910\n",
      "27062\n",
      "27114\n",
      "27259\n",
      "27769\n",
      "30687\n",
      "31697\n",
      "34153\n",
      "36810\n",
      "37041\n",
      "37267\n",
      "40140\n",
      "41659\n",
      "41665\n",
      "43227\n",
      "43810\n",
      "49969\n",
      "50887\n",
      "51074\n",
      "51129\n",
      "52904\n",
      "52991\n",
      "53235\n",
      "53290\n",
      "55768\n",
      "56248\n",
      "56836\n"
     ]
    }
   ],
   "source": [
    "for key in cleaned_tokenized_lyrics:\n",
    "    if \"love you\" in \" \".join(cleaned_tokenized_lyrics[key]):\n",
    "        #print(key)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming words\n",
    "ps = PorterStemmer()\n",
    "ps.stem(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTUAL IMPLEMENTATION START HERE\n",
    "Step 1: Get inputs\n",
    "2: Use genre to search for songs\n",
    "3: Find exact matching words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gorge'])\n",
      "dict_keys(['gorge'])\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Find exact matching words \n",
    "# \"genre_input\" is the user inputted genre\n",
    "user_genre_input = \"gorge\"\n",
    "\n",
    "#Tokenize and clean(Remove stop words) user input\n",
    "#clean_genre_input : {0:[Cleaned user input]}\n",
    "clean_genre_input = remove_stop_words(stopwords.words('english'),{0:tokenize(user_genre_input)})\n",
    "\n",
    "#A dict with KEYS as unique NON STOP words !!from the user input!! and VALUES as a list of all the songs(their row numbers) the word appears in\n",
    "possible_songs_dict = {}\n",
    "\n",
    "for word in clean_genre_input[0]:\n",
    "    if clean_song_count.get(word) is not None:\n",
    "        #Clean_song_count: A dict with KEYS as unique NON STOP words and VALUES as a list of all the songs(their row numbers) the word appears in\n",
    "        possible_songs_dict[word] = clean_song_count[word]\n",
    "print(possible_songs_dict.keys())\n",
    "    \n",
    "#Stem the words that can't be found in song lyrics and add them to stemmed_user_input\n",
    "stemmed_user_input = []\n",
    "#Stem the words that can't be found in song lyrics and add them to stemmed_user_input, preserve words that are already found in song lyrics\n",
    "stemmed_user_input_preserve_original = []\n",
    "for word in clean_genre_input[0]:\n",
    "    if possible_songs_dict.get(word) is None:\n",
    "        stemmed_user_input_word = ps.stem(word)\n",
    "        stemmed_user_input.append(stemmed_user_input_word)\n",
    "        stemmed_user_input_preserve_original.append(stemmed_user_input_word)\n",
    "    else:\n",
    "        stemmed_user_input_preserve_original.append(word)\n",
    "\n",
    "#Update the list of possible songs by searching for stemmed words in the songs\n",
    "for word in stemmed_user_input:\n",
    "    if clean_song_count.get(word) is not None:\n",
    "        possible_songs_dict[word] = clean_song_count[word]\n",
    "print(possible_songs_dict.keys())\n",
    "\n",
    "#Get the songs that has the most number of relevant words from user input\n",
    "most_common_songs = []\n",
    "if possible_songs_dict:\n",
    "    # Count occurrences of each song index\n",
    "    song_counts = Counter(song for song_list in possible_songs_dict.values() for song in song_list)\n",
    "    # Find the maximum count\n",
    "    max_number = max(song_counts.values(), default=0)\n",
    "    # Return the song indices that appear the most\n",
    "    most_common_songs = [song for song, count in song_counts.items() if count == max_number]\n",
    "\n",
    "#For words in the user input that don't exist in any songs, find the synonyms\n",
    "# A dictionary with KEYS as user input words that don't exist in any songs, VALUES as a list of their synonyms\n",
    "word_synonym_dict = {}\n",
    "for word in stemmed_user_input_preserve_original:\n",
    "    if possible_songs_dict.get(word) is None:\n",
    "        set_of_synonyms = get_synonyms_of_word(word)\n",
    "        word_synonym_dict[word] = list(set_of_synonyms)\n",
    "print(word_synonym_dict)\n",
    "##NEED TO FIX: Not sure how to incorporate synonyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53789, 28893, 53663]\n"
     ]
    }
   ],
   "source": [
    "print(most_common_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number(including repeats) of inputted words in song\n",
    "if len(most_common_songs) > 40:\n",
    "    most_common_songs = most_common_songs[:40]  \n",
    "\n",
    "sum_of_words_dict = {}\n",
    "\n",
    "for word in clean_genre_input[0]:\n",
    "    if word not in inverted_index:\n",
    "        continue  \n",
    "\n",
    "    inv_index_list = inverted_index[word]\n",
    "    for song_idx, num_words in inv_index_list:\n",
    "        if song_idx not in most_common_songs:\n",
    "            continue\n",
    "\n",
    "        sum_of_words_dict[song_idx] = sum_of_words_dict.get(song_idx, 0) + num_words\n",
    "\n",
    "top_30_songs = sorted(sum_of_words_dict, key=sum_of_words_dict.get, reverse=True)[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53789, 28893, 53663]\n"
     ]
    }
   ],
   "source": [
    "print(top_30_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find songs without(or with very little) antonyms\n",
    "def get_antonyms(word):\n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            if i.antonyms():\n",
    "                antonyms.append(i.name().replace(\"_\", \" \").lower())\n",
    "    return set(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get all antonyms for user input words\n",
    "word_antonyms = {word: get_antonyms(word) for word in clean_genre_input[0]}\n",
    "\n",
    "# for the top_30_songs, find the songs with these antonyms\n",
    "song_antonym_counts = Counter()\n",
    "\n",
    "for word, antonyms in word_antonyms.items():\n",
    "    for antonym in antonyms:\n",
    "        if antonym in clean_song_count:\n",
    "            for song in clean_song_count[antonym]:\n",
    "                if song in top_30_songs: \n",
    "                    song_antonym_counts[song] += 1 \n",
    "\n",
    "# Step 3: Add songs with no antonyms with values of 0\n",
    "for song in top_30_songs:\n",
    "    if song not in song_antonym_counts:\n",
    "        song_antonym_counts[song] = 0\n",
    "\n",
    "# Step 4: Sort songs by least distinct antonyms\n",
    "filtered_songs = sorted(song_antonym_counts.keys(), key=lambda song: song_antonym_counts[song])\n",
    "\n",
    "filtered_songs = filtered_songs[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10853, 13130, 41152, 44258, 55572]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Sort the input_song_list based on the polarity score(pos, neg, neutral, compound(Compound being -1 to 1, with -1 being neg and 1 being pos))\n",
    "def sort_polarity_scores(input_song_list, cleaned_tokenized_lyrics, polarity_type=\"compound\"):\n",
    "    sia = SentimentIntensityAnalyzer() \n",
    "    dict_of_polarity_scores = {}\n",
    "\n",
    "    for song_row_number in input_song_list:\n",
    "        if song_row_number in cleaned_tokenized_lyrics:\n",
    "            dict_of_polarity_scores[song_row_number] = sia.polarity_scores(\" \".join(cleaned_tokenized_lyrics[song_row_number]))\n",
    "\n",
    "    # Sort songs by the specified polarity score in descending order\n",
    "    sorted_songs = sorted(dict_of_polarity_scores, key=lambda x: dict_of_polarity_scores[x][polarity_type], reverse=True)\n",
    "\n",
    "    return sorted_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes too long to run\n",
    "result = sort_polarity_scores(filtered_songs, cleaned_tokenized_lyrics, \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28893, 53789, 53663]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'allan', 'coe', 'dedication', 'told', 'george', 'jones', 'full', 'whiskey', 'sing', 'anymore', 'said', 'skinny', 'sickly', 'looking', 'told', 'em', 'one', 'best', 'friends', 'whiskey', 'never', 'make', 'gorge', 'jones', 'quit', 'singing', 'george', 'wagon', 'done', 'song', 'sings', 'like', 'wishes', 'drink', 'last', 'week', 'spent', 'whole', 'pay', 'check', 'whiskey', 'know', 'friday', 'night', 'oh', 'drink', 'till', 'falls', 'order', 'one', 'round', 'go', 'home', 'bottle', 'hand', 'thing', 'hold', 'bottle', 'hand', 'know', 'never', 'share', 'man', 'glad', 'introduced', 'us', 'best', 'faithful', 'bottle', 'hand', 'told', 'george', 'changing', 'diapers', 'sure', 'become', 'drag', 'clean', 'house', 'cook', 'kind', 'bag', 'said', 'needed', 'someone', 'love', 'understand', 'left', 'bottle', 'hand', 'thing', 'hold', 'bottle', 'hand', 'know', 'never', 'share', 'man', 'glad', 'introduced', 'us', 'best']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_tokenized_lyrics[28893])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
